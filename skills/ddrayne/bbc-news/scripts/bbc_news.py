#!/usr/bin/env python3
"""
BBC æ–°é—»å‘½ä»¤è¡Œå·¥å…· - ä» RSS è®¢é˜…è·å–å¹¶æ˜¾ç¤º BBC æ–°é—»æŠ¥é“
"""
import argparse
import sys
from datetime import datetime

try:
    import feedparser
except ImportError:
    print("é”™è¯¯: æœªæ‰¾åˆ° feedparser åº“ã€‚è¯·å®‰è£…: pip install feedparser", file=sys.stderr)
    sys.exit(1)

# BBC æ–°é—» RSS è®¢é˜…
FEEDS = {
    "top": "https://feeds.bbci.co.uk/news/rss.xml",
    "uk": "https://feeds.bbci.co.uk/news/uk/rss.xml",
    "world": "https://feeds.bbci.co.uk/news/world/rss.xml",
    "business": "https://feeds.bbci.co.uk/news/business/rss.xml",
    "politics": "https://feeds.bbci.co.uk/news/politics/rss.xml",
    "health": "https://feeds.bbci.co.uk/news/health/rss.xml",
    "education": "https://feeds.bbci.co.uk/news/education/rss.xml",
    "science": "https://feeds.bbci.co.uk/news/science_and_environment/rss.xml",
    "technology": "https://feeds.bbci.co.uk/news/technology/rss.xml",
    "entertainment": "https://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml",
    "england": "https://feeds.bbci.co.uk/news/england/rss.xml",
    "scotland": "https://feeds.bbci.co.uk/news/scotland/rss.xml",
    "wales": "https://feeds.bbci.co.uk/news/wales/rss.xml",
    "northern-ireland": "https://feeds.bbci.co.uk/news/northern_ireland/rss.xml",
    "africa": "https://feeds.bbci.co.uk/news/world/africa/rss.xml",
    "asia": "https://feeds.bbci.co.uk/news/world/asia/rss.xml",
    "australia": "https://feeds.bbci.co.uk/news/world/australia/rss.xml",
    "europe": "https://feeds.bbci.co.uk/news/world/europe/rss.xml",
    "latin-america": "https://feeds.bbci.co.uk/news/world/latin_america/rss.xml",
    "middle-east": "https://feeds.bbci.co.uk/news/world/middle_east/rss.xml",
    "us-canada": "https://feeds.bbci.co.uk/news/world/us_and_canada/rss.xml",
}


def fetch_news(section="top", limit=10, format="text"):
    """ä» RSS è®¢é˜…è·å– BBC æ–°é—»æŠ¥é“"""
    if section not in FEEDS:
        print(f"é”™è¯¯: æœªçŸ¥éƒ¨åˆ† '{section}'", file=sys.stderr)
        print(f"å¯ç”¨éƒ¨åˆ†: {', '.join(sorted(FEEDS.keys()))}", file=sys.stderr)
        return 1

    feed_url = FEEDS[section]
    feed = feedparser.parse(feed_url)

    if feed.bozo:
        print(f"é”™è¯¯: æ— æ³•è§£ææ¥è‡ª {feed_url} çš„è®¢é˜…", file=sys.stderr)
        return 1

    entries = feed.entries[:limit]

    if format == "json":
        import json
        stories = []
        for entry in entries:
            stories.append({
                "title": entry.title,
                "link": entry.link,
                "description": entry.get("description", ""),
                "published": entry.get("published", ""),
            })
        print(json.dumps(stories, indent=2))
    else:
        # æ–‡æœ¬æ ¼å¼
        section_title = feed.feed.get("title", f"BBC æ–°é—» - {section.title()}")
        print(f"\n{section_title}")
        print("=" * len(section_title))
        print()

        for i, entry in enumerate(entries, 1):
            print(f"{i}. {entry.title}")
            if hasattr(entry, "description") and entry.description:
                # ä»æè¿°ä¸­ç§»é™¤ HTML æ ‡ç­¾
                import re
                desc = re.sub(r'<[^>]+>', '', entry.description)
                print(f"   {desc}")
            print(f"   ğŸ”— {entry.link}")
            if hasattr(entry, "published"):
                print(f"   ğŸ“… {entry.published}")
            print()

    return 0


def list_sections():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨éƒ¨åˆ†"""
    print("\nå¯ç”¨çš„ BBC æ–°é—»éƒ¨åˆ†:")
    print("=" * 40)
    print("\nä¸»è¦éƒ¨åˆ†:")
    main = ["top", "uk", "world", "business", "politics", "health", 
            "education", "science", "technology", "entertainment"]
    for section in main:
        if section in FEEDS:
            print(f"  â€¢ {section}")
    
    print("\nè‹±å›½åœ°åŒº:")
    regional = ["england", "scotland", "wales", "northern-ireland"]
    for section in regional:
        if section in FEEDS:
            print(f"  â€¢ {section}")
    
    print("\nä¸–ç•Œåœ°åŒº:")
    world = ["africa", "asia", "australia", "europe", 
             "latin-america", "middle-east", "us-canada"]
    for section in world:
        if section in FEEDS:
            print(f"  â€¢ {section}")
    print()


def main():
    parser = argparse.ArgumentParser(
        description="ä» RSS è®¢é˜…è·å– BBC æ–°é—»æŠ¥é“",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                          # å¤´æ¡æ–°é—»ï¼ˆé»˜è®¤ï¼‰
  %(prog)s uk                       # è‹±å›½æ–°é—»
  %(prog)s world --limit 5          # ä¸–ç•Œå‰ 5 æ¡æ–°é—»
  %(prog)s technology --json        # æŠ€æœ¯æ–°é—»ï¼ˆJSON æ ¼å¼ï¼‰
  %(prog)s --list                   # åˆ—å‡ºæ‰€æœ‰å¯ç”¨éƒ¨åˆ†
        """
    )
    parser.add_argument(
        "section",
        nargs="?",
        default="top",
        help="æ–°é—»éƒ¨åˆ†ï¼ˆé»˜è®¤: topï¼‰"
    )
    parser.add_argument(
        "-l", "--limit",
        type=int,
        default=10,
        help="è¦è·å–çš„æ–°é—»æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰"
    )
    parser.add_argument(
        "-f", "--format",
        choices=["text", "json"],
        default="text",
        help="è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤: textï¼‰"
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨éƒ¨åˆ†"
    )

    args = parser.parse_args()

    if args.list:
        list_sections()
        return 0

    return fetch_news(args.section, args.limit, args.format)


if __name__ == "__main__":
    sys.exit(main())
